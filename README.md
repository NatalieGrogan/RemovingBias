# MA493 Final Project
MA493, Math for Social Justice, Final Project, Natalie Grogn and Kyra Stash

   The objective of this project was very broad. We were told to use the skills we had learned in class to tackle a current problem in social justice. My partner, Kyra, and I chose to take on Bias in Algorithms. We followed the method described in "[A statistical framework for fair predictive algorithms](https://arxiv.org/pdf/1610.08077.pdf)" by Kristian Lum and James E. Johndrow from 2016.  We used a dataset from UCI Machine Learning Repository called “[Communities and Crime Data Set](https://archive.ics.uci.edu/ml/datasets/communities+and+crime#::text=UCI%20Machine%20Learning%20Repository%3A%20Communities%20and%20Crime%20Data%20Set&text=Abstract%3A%20Communities%20within%20the%20United,from%20the%201995%20FBI%20UCR)” This dataset combined socio-economic information on 1600+ cities in North America from the 1990 US Census and crime data from the 1995 FBI UCR. This dataset was far from an ideal candidate for use in implementing the papers method. However due limited time available for the project we were unable to find a more suitable dataset. 
	
	
   The method described in the paper is to find the conditional probability of each variable given your biasing characteristic, e.g. race. This is accomplished via regression. The type of regression used depends on the variable in question. The difference between the regressions predicted value and the real value for each variable is used to find the conditional probabilities. These conditional probabilities are then used to create a new regression which is used to predict the desired outcome. In our case it was violent crimes per 100,000 citizens in a city.
	
	
   Our implementation was able to create a model that predicted similar violent crime rate for cities with similar socio-economic factors irregardless of the cities racial makeup and wildly different violent crime rates for cities with different socio-economic factors regardless of racial makeup of the city. This reduction in bias came at virtually no loss in overall fit of the regression, a reduction of .0001 r value was observed.